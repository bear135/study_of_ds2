{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### AICE associate sample test\n",
    "- https://aice.study/certi/practice \n",
    "- 14문항, 90분 (합격기준 80점 이상)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q1. scikit_learn을 sk로 임포트 하라 \n",
    "import sklearn as sk \n",
    "\n",
    "#Q2. pandas를 pd로 임포트 하라 \n",
    "import pandas as pd "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q3. A0007IT파일을 df_a에,signal.csv파일을 df_b로 읽어오고, RID를 키로 inner join 하여 df를 만들어라\n",
    "df_a = pd.read_json('A0007IT.json')\n",
    "df_b = pd.read_csv('signal.csv')\n",
    "\n",
    "df = merge(df_a, df_b, on='RID', how='Inner')\n",
    "df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' \n",
    "#Q4. Address1(주소1)에 대해 countplot그래프로 만들고 아래 가이드에 따라 답하세요.\n",
    "- Seaborn을 활용하세요.\n",
    "- 첫번째, Address1(주소1)에 대해서 분포를 보여주는 countplot그래프 그리세요.\n",
    "- 두번째, 지역명이 없는 '-'에 해당되는 row(행)을 삭제하세요.\n",
    "- 세번째, 그래프를 보고 해석한 것으로 옳지 않은 선택지를 아래에서 골라 '답안04' 변수에 저장하세요 (예. 답안04=3)\n",
    "- 1) Countplot 그래프에서 Address1(주소1) 분포를 확인시 '경기도' 분포가 제일 크다\n",
    "- 2) Address1(주소1) 분포를 보면 '인천광역시' 보다 '서울특별시'가 더 크다\n",
    "- 3) 지역명이 없는 '-'에 해당되는 row(행)가 2개 있다.\n",
    "''' \n",
    "import seaborn as sns\n",
    "print(df['Address1'].value_counts()) \n",
    "\n",
    "df2 = df2[df['Address1' != '-']\n",
    "sns.countplot(data=df2, x='Address1')\n",
    "\n",
    "답안04 = 3 \n",
    "print('답안04 =' , 답안04) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "#Q5. 실주행시간과 평균시속의 분포를 같이 확인하려고 합니다.\n",
    "Time_Driving(실주행시간)과 Speed_Per_Hour(평균시속)을 jointplot 그래프로 만드세요.\n",
    "Seaborn을 활용하세요.X축에는 Time_Driving(실주행시간)을 표시하고 Y축에는 Speed_Per_Hour(평균시속)을 표시하세요.\n",
    "'''\n",
    "sns.jointplot(x='Time_Driving', y='Speed_Per_Hour', data=df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "#Q6. 위의 jointplot 그래프에서 시속 300이 넘는 이상치를 발견할 수 있습니다.\n",
    "jointplot 그래프에서 발견한 이상치 1개를 삭제하세요.(대상 데이터프레임: df) \n",
    "jointplot 그래프를 보고 시속 300 이상되는 이상치를 찾아 해당 행(Row)을 삭제하세요.\n",
    "전처리 반영 후에 새로운 데이터프레임 변수명 df_temp에 저장하세요.\n",
    "'''\n",
    "df_temp = df[df['Speed_Per_Hour'] < 300].drop('RID', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "#Q7. 모델링 성능을 제대로 얻기 위해서 결측치 처리는 필수입니다.아래 가이드를 따라 결측치 처리하세요.(대상 데이터프레임: df_temp) \n",
    "- 결측치를 확인하는 코드를 작성하세요.\n",
    "- 결측치가 있는 행(raw)를 삭제 하세요.\n",
    "- 전처리 반영된 결과를 새로운 데이터프레임 변수명 df_na에 저장하세요.\n",
    "'''\n",
    "num_na = df_temp.isnull().sum()\n",
    "print(num_na)\n",
    "\n",
    "df_na = df_temp.dropna(axis=0)\n",
    "답안07 = num_na.sum()\n",
    "print('답안07 = ', 답안07) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "#Q8. 모델링 성능을 제대로 얻기 위해서 불필요한 변수는 삭제해야 합니다.아래 가이드를 따라 불필요 데이터를 삭제 처리하세요.(대상 데이터프레임: df_na)\n",
    "- 'Time_Departure', 'Time_Arrival' 2개 컬럼을 삭제하세요.\n",
    "- 전처리 반영된 결과를 새로운 데이터프레임 변수명 df_del에 저장하세요.\n",
    "'''\n",
    "drop_list = ['Time_Departure' , 'Time_Arrival' ]\n",
    "df_del = df_na.drop(drop_list , axis=1) \n",
    "df_del "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "#Q9. 원-핫 인코딩(One-hot encoding)은 범주형 변수를 1과 0의 이진형 벡터로 변환하기 위하여 사용하는 방법입니다.\n",
    "원-핫 인코딩으로 아래 조건에 해당하는 컬럼 데이터를 변환하세요.(대상 데이터프레임: df_del)\n",
    "- 원-핫 인코딩 대상: object 타입의 전체 컬럼\n",
    "- 활용 함수: pandas의 get_dummies\n",
    "- 해당 전처리가 반영된 결과를 데이터프레임 변수 df_preset에 저장해 주세요.\n",
    "'''\n",
    "\n",
    "object_columns = df_del.select_dtypes(include=['object']).columns\n",
    "df_preset = pd.get_dummies(df_del, columns=object_columns)\n",
    "\n",
    "## 참고 : 아래 코드는 object / category type 모두를 원-핫 코딩한다. \n",
    "df_preset = pd.get_dummies(df_del) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "#Q10. 훈련과 검증 각각에 사용할 데이터셋을 분리하려고 합니다. Time_Driving(실주행시간) 컬럼을 label값 y로, 나머지 컬럼을 feature값 X로 할당한 후 \n",
    "훈련데이터셋과 검증데이터셋으로 분리하세요.(대상 데이터프레임: df_preset)\n",
    "\n",
    "[Scikit-learn의 train_test_split 함수를 활용]\n",
    "- 훈련 데이터셋 label: y_train, 훈련 데이터셋 Feature: X_train\n",
    "- 검증 데이터셋 label: y_valid, 검증 데이터셋 Feature: X_valid\n",
    "- 훈련 데이터셋과 검증데이터셋 비율은 80:20, random_state: 42\n",
    "\n",
    "[sklearn.preprocessing의 MinMaxScaler 함수 사용] \n",
    "- 훈련데이터셋의 Feature는 MinMaxScaler의 fit_transform 함수를 활용하여 X_train 변수로 할당\n",
    "- 검증데이터셋의 Feature는 MinMaxScaler의 transform 함수를 활용하여 X_valid 변수로 할당\n",
    "'''\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler, RobustScaler\n",
    "\n",
    "x = df_preset.drop('Time_Driving', axis=1)\n",
    "y = df_preset['Time_Driving']\n",
    "\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(x,y, test_size=0.2, random_state=42)\n",
    "print(X_train.shape, X_valid.shape, y_train.shape, y_valid.shape)\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_valid = scaler.transform(X_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "#Q11. Time_Driving(실주행시간)을 예측하는 머신러닝 모델을 만들려고 합니다.아래 가이드에 따라 다음 모델을 만들고 학습을 진행하세요.\n",
    "\n",
    "[의사결정나무(Decisiontree)]\n",
    "- 트리의 최대 깊이: 5로 설정\n",
    "- 노드를 분할하기 위한 최소한의 샘플 데이터 수(min_sample_split): 3으로 설정\n",
    "- random_state: 120으로 설정\n",
    "- 의사결정나무(decision tree) 모델을 dt 변수에 저장해주세요.\n",
    "\n",
    "[랜덤포레스트(RandomForest)]\n",
    "- 트리의 최대 깊이: 5로 설정\n",
    "- 노드를 분할하기 위한 최소한의 샘플 데이터 수(min_sample_split): 3으로 설정\n",
    "- random_state: 120으로 설정\n",
    "- 랜덤포레스트(RandomForest) 모델을 rf 변수에 저장해주세요.\n",
    "\n",
    "[선형회귀(LinearRegression)]\n",
    "- 선형회rnl(LinearRegression)모델을 lr 변수에 저장해주세요.\n",
    "\n",
    "[K최근접(KNeighborsRegressor)]\n",
    "- 가장 가까운 이웃의 'K'개의 값(n_neighbors): 5로 설정\n",
    "- weights를 'distance'로 설정 # distance와 uniform이 있음\n",
    "- K최근접(KNeighborsRegressor)모델을 kr 변수에 저장해주세요.\n",
    "'''\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "\n",
    "## model train \n",
    "dt = DecisionTreeRegressor(max_depth=5, min_samples_split=3, random_state=120)\n",
    "rf = RandomForestRegressor(max_depth=5, min_samples_split=3, random_state=120)\n",
    "lr = LinearRegression()\n",
    "kr = KNeighborsRegressor(n_neighbors=5, weights='distance')\n",
    "\n",
    "# XGBRegressor(max_depth=5, random_state=120)\n",
    "# LGBMRegressor(random_state=120,verbose=-1)\n",
    "\n",
    "dt.fit(X_train, y_train)\n",
    "rf.fit(X_train, y_train)\n",
    "lr.fit(X_train, y_train)\n",
    "kr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "#Q12. 위 모델들의 성능을 평가하려고 합니다.예측 결과의 mae(Mean Absolute Error)를 구하세요. 성능 평가는 검증 데이터셋 (X_valid, y_valid)을 활용하세요.\n",
    "\n",
    "[의사결정나무(Decisiontree) 모델]\n",
    "- 11번 문제에서 만든 의사결정나무(decision tree) 모델로 y값을 예측(predict)하여 y_pred_dt에 저장하세요.\n",
    "- 검증 정답(y_valid)과 예측값(y_pred_dt)의 mae(Mean Absolute Error)를 구하고 dt_mae 변수에 저장하세요.\n",
    "\n",
    "[랜덤포레스트(RandomForest) 모델]\n",
    "- 11번 문제에서 만든 랜덤포레스트(RandomForest) 모델로 y값을 예측(predict)하여 y_pred_rf에 저장하세요.\n",
    "- 검증 정답(y_valid)과 예측값(y_pred_rf)의 mae(Mean Absolute Error)를 구하고 rf_mae 변수에 저장하세요.\n",
    "\n",
    "[ 선형회쉬(LinearRegression) 모델] \n",
    "- 11번 문제에서 만든 선형회쉬(LinearRegression) 모델로 y값을 예측(predict)하여 y_pred_lr에 저장하세요.\n",
    "- 검증 정답(y_valid)과 예측값(y_pred_lr)의 mae(Mean Absolute Error)를 구하고 lr_mae 변수에 저장하세요.\n",
    "\n",
    "[K최근접(KNeighborsRegressor) 모델]\n",
    "- 11번 문제에서 만든 K최근접(KNeighborsRegressor) 모델로 y값을 예측(predict)하여 y_pred_kr에 저장하세요.\n",
    "- 검증 정답(y_valid)과 예측값(y_pred_kr)의 mae(Mean Absolute Error)를 구하고 kr_mae 변수에 저장하세요.\n",
    "\n",
    "훈련시킨 모델들에 대한 mae 성능평가 결과를 확인하여 가장 성능이 좋은 모델 이름을 답안12 변수에 저장하세요\n",
    "예. 답안12 = 'Decisiontree' 혹은 'RandomForest' 혹은 'LinearRegression' 혹은 'KNeighborsRegressor'\n",
    "'''\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "y_pred_dt = dt.predict(X_valid)\n",
    "dt_mae = mean_absolute_error(y_valid, y_pred_dt)\n",
    "print('dt MAE:', dt_mae)\n",
    "\n",
    "y_pred_rf = rf.predict(X_valid)\n",
    "rf_mae = mean_absolute_error(y_valid, y_pred_rf)\n",
    "print('rf MAE:', rf_mae)\n",
    "\n",
    "y_pred_lr = lr.predict(X_valid)\n",
    "lr_mae = mean_absolute_error(y_valid, y_pred_lr)\n",
    "print('lr MAE:', lr_mae)\n",
    "\n",
    "y_pred_kr = kr.predict(X_valid)\n",
    "kr_mae = mean_absolute_error(y_valid, y_pred_kr)\n",
    "print('kr MAE:', kr_mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.layers import Dense, Activation, Dropout, BatchNormalization\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "tf.random.set_seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "#Q13. Time_Driving(실주행시간)을 예측하는 딥러닝 모델을 만들려고 합니다. 아래 가이드에 따라 모델링하고 학습을 진행하세요.\n",
    "- Tensoflow framework를 사용하여 딥러닝 모델을 만드세요.\n",
    "- 히든레이어(hidden layer) 2개이상으로 모델을 구성하세요.\n",
    "- dropout 비율 0.2로 Dropout 레이어 1개를 추가해 주세요.\n",
    "- 손실함수는 MSE(Mean Squared Error)를 사용하세요.\n",
    "- 하이퍼파라미터 epochs: 30, batch_size: 16으로 설정해주세요.\n",
    "- 각 에포크마다 loss와 metrics 평가하기 위한 데이터로 X_valid, y_valid 사용하세요.\n",
    "- 학습정보는 history 변수에 저장해주세요\n",
    "'''\n",
    "model = Sequential()\n",
    "\n",
    "nfeatures = X_train.shape[1]\n",
    "model.add(Dense(128, activation='relu', input_shape=(nfeatures,)))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(16, activation='relu'))\n",
    "model.add(Dense(1))\n",
    "\n",
    "model.compile(optimizer='adam', loss='mse',metrics=['mae','mse'])\n",
    "# es = EarlyStopping(monitor='val_loss', patience=4, mode='min', verbose=1)    # val_loss\n",
    "\n",
    "history = model.fit(X_train, y_train, \n",
    "                    batch_size=16, \n",
    "                    epochs=30, \n",
    "                    # callbacks=[es],\n",
    "                    validation_data=(X_valid, y_valid), \n",
    "                    verbose=1).history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "#Q14. 위 딥러닝의 성능을 평가하려고 합니다. Matplotlib 라이브러리를 활용해서 학습 mse와 검증 mse를 그래프로 표기하세요.\n",
    "- 1개의 그래프에 학습 mse와 검증 mse 2가지를 모두 표기하세요.\n",
    "- 위 2가지 각각의 범례를 'mse'와 'val_mse'로 표기하세요.\n",
    "- 그래프의 타이틀은 'Model MSE'로 표기하세요.\n",
    "- X축에는 'Epochs'라고 표시하고 Y축에는 \"MSE'라고 표기하세요.\n",
    "'''\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.legend(['mse','val_mse'])\n",
    "plt.title('Model MSE')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('MSE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "- 1개의 그래프에 학습 mse와 검증 mse 2가지를 모두 표기하세요.\n",
    "- 위 2가지 각각의 범례를 'mse'와 'val_mse'로 표기하세요.\n",
    "- 그래프의 타이틀은 'Model MSE'로 표기하세요.\n",
    "- X축에는 'Epochs'라고 표시하고 Y축에는 \"MSE'라고 표기하세요.\n",
    "- 위 딥러닝 모델에 대해 검증 정답(y_valid)과 예측값(y_pred_dl)의 mae(Mean Absolute Error)를 구하고 dl_mae 변수에 저장하세요.\n",
    "'''\n",
    "\n",
    "def dl_history_plot(history):\n",
    "    plt.figure(figsize=(16,4))\n",
    "    plt.subplot(1,2,1)\n",
    "    plt.plot(history['loss'], label='loss', marker = '.')\n",
    "    plt.plot(history['val_loss'], label='val_loss', marker = '.')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "\n",
    "    plt.subplot(1,2,2)\n",
    "    plt.plot(history['mse'], label='mse', marker = '.')\n",
    "    plt.plot(history['val_mse'], label='val_mse', marker = '.')\n",
    "    plt.ylabel('MSE')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "#chart \n",
    "dl_history_plot(history)\n",
    "\n",
    "#mae \n",
    "y_pred_dl = model.predict(X_valid, verbose=1)\n",
    "dl_mae = mean_absolute_error(y_valid, y_pred_dl)\n",
    "print('DL MAE:', dl_mae)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
