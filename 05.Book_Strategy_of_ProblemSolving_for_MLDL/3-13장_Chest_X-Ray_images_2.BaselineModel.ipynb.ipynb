{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":23812,"sourceType":"datasetVersion","datasetId":17810}],"dockerImageVersionId":30823,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"--- \n### 3-13장 Chest X-Ray images 2. Baseline Model  \n- https://www.kaggle.com/datasets/paultimothymooney/chest-xray-pneumonia \n- 경진대회가 아닌 이미지셋만 주어짐 \n- X-ray 이미지로 부터 정상 또는 폐렴 여부를 판별하는 문제 \n- train / val /test 폴더에 각각 Normal/Pneumonia 폴더가 있다. (정상/폐렴의 이미지)\n- 평가지표로 정확도, 재현율, F1-score 사용 \n- Model: efficientnet-b0, Optimizer: Adam 사용 \n---","metadata":{}},{"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport os\n\nfile_count = 0  # 출력한 파일 개수를 추적\nmax_files = 10  # 출력할 파일의 최대 개수\n\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n        file_count += 1\n        if file_count >= max_files:\n            break\n    if file_count >= max_files:\n        break","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-29T14:17:34.675226Z","iopub.execute_input":"2024-12-29T14:17:34.675610Z","iopub.status.idle":"2024-12-29T14:17:34.687681Z","shell.execute_reply.started":"2024-12-29T14:17:34.675549Z","shell.execute_reply":"2024-12-29T14:17:34.686928Z"}},"outputs":[{"name":"stdout","text":"/kaggle/input/chest-xray-pneumonia/chest_xray/chest_xray/.DS_Store\n/kaggle/input/chest-xray-pneumonia/chest_xray/chest_xray/val/.DS_Store\n/kaggle/input/chest-xray-pneumonia/chest_xray/chest_xray/val/PNEUMONIA/person1947_bacteria_4876.jpeg\n/kaggle/input/chest-xray-pneumonia/chest_xray/chest_xray/val/PNEUMONIA/person1946_bacteria_4875.jpeg\n/kaggle/input/chest-xray-pneumonia/chest_xray/chest_xray/val/PNEUMONIA/person1952_bacteria_4883.jpeg\n/kaggle/input/chest-xray-pneumonia/chest_xray/chest_xray/val/PNEUMONIA/person1954_bacteria_4886.jpeg\n/kaggle/input/chest-xray-pneumonia/chest_xray/chest_xray/val/PNEUMONIA/person1951_bacteria_4882.jpeg\n/kaggle/input/chest-xray-pneumonia/chest_xray/chest_xray/val/PNEUMONIA/person1946_bacteria_4874.jpeg\n/kaggle/input/chest-xray-pneumonia/chest_xray/chest_xray/val/PNEUMONIA/person1949_bacteria_4880.jpeg\n/kaggle/input/chest-xray-pneumonia/chest_xray/chest_xray/val/PNEUMONIA/.DS_Store\n","output_type":"stream"}],"execution_count":19},{"cell_type":"code","source":"# 1. 시드고정 \nimport torch \nimport random \nimport numpy as np \nimport pandas as pd \nimport os\n\nseed = 50 \nos.environ['PYTHONHASHSEED'] = str(seed)\nrandom.seed(seed)\nnp.random.seed(seed)\ntorch.manual_seed(seed)\ntorch.cuda.manual_seed(seed)\ntorch.cuda.manual_seed_all(seed)\ntorch.backends.cudnn.deterministic = True\ntorch.backends.cudnn.benchmark = False\ntorch.backends.cudnn.enabled = False\n\n# 2.GPU setting \ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\ndevice","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-29T13:57:22.428656Z","iopub.execute_input":"2024-12-29T13:57:22.429066Z","iopub.status.idle":"2024-12-29T13:57:22.442982Z","shell.execute_reply.started":"2024-12-29T13:57:22.429027Z","shell.execute_reply":"2024-12-29T13:57:22.442065Z"}},"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"device(type='cuda')"},"metadata":{}}],"execution_count":4},{"cell_type":"markdown","source":"- 주어진 데이터는 train/valid set이 폴더단위로 구분되어 있다. \n- 따라서 data split와 Dataset class 정의가 불필요 --> ImageFolder로 간단하게 데이터셋 생성가능  ","metadata":{}},{"cell_type":"code","source":"# 3. 데이터 로딩 \ndata_path = '/kaggle/input/chest-xray-pneumonia/chest_xray/'\ntrain_path = os.path.join(data_path, 'train/')\nval_path = os.path.join(data_path, 'val/')\ntest_path = os.path.join(data_path, 'test/')\n\n# 4. 이미지 증강을 위한 데이터 변환기 정의 \nfrom torchvision import transforms \n\ntransform_train = transforms.Compose([transforms.Resize((250,250)),   # 이미지 크기를 250x250으로 \n                                      transforms.CenterCrop(180),     # 이미지 가운데 부분을 180x180 만큼 잘라냄 \n                                      transforms.RandomHorizontalFlip(0.5), # 50% 확률로 수평변환 \n                                      transforms.RandomVerticalFlip(0.2),   # 20% 확률로 수직변환 \n                                      transforms.RandomRotation(20),        # +/- 20도 랜덤 회전 \n                                      transforms.ToTensor(), \n                                      transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))  # RGB 평균&표준편차로 표준화 \n                                      ])\n\ntransform_test = transforms.Compose([transforms.Resize((250,250)), \n                                      transforms.CenterCrop(180),                                       \n                                      transforms.ToTensor(), \n                                      transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))\n                                      ])\n\n# 5. 데이터셋 생성 \n# ImageFolder는 root의 경로에 있는 이미지들을 바로 데이터셋으로 만들어준다. \nfrom torchvision.datasets import ImageFolder  \n\ndataset_train = ImageFolder(root=train_path, transform=transform_train)\ndataset_valid = ImageFolder(root=test_path, transform=transform_test)\n\n# 6. 멀티프로세싱 설정, 제너레이터 시드고정 \ndef seed_worker(worker_id): \n    worker_seed = torch.initial_seed() % 2**32\n    random.seed(worker_seed)\n    np.random.seed(worker_seed)\n\ng = torch.Generator()\ng.manual_seed(0)\n\n# 7. 데이터로더 생성 \nfrom torch.utils.data import DataLoader\nbatch_size = 8\nloader_train = DataLoader(dataset=dataset_train, batch_size=batch_size, shuffle=True, worker_init_fn=seed_worker, generator=g, num_workers=2 )\nloader_valid = DataLoader(dataset=dataset_valid, batch_size=batch_size, shuffle=False, worker_init_fn=seed_worker, generator=g, num_workers=2 )","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-29T13:59:05.622327Z","iopub.execute_input":"2024-12-29T13:59:05.622761Z","iopub.status.idle":"2024-12-29T13:59:07.070235Z","shell.execute_reply.started":"2024-12-29T13:59:05.622726Z","shell.execute_reply":"2024-12-29T13:59:07.069528Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"# 8. efficientnet 모델 임포트 및 디바이스 할당 \n!pip install efficientnet-pytorch==0.7.1\nfrom efficientnet_pytorch import EfficientNet\n\nmodel = EfficientNet.from_pretrained('efficientnet-b0', num_classes=2 )  # efficientnet-b0 : 약 4백만개의 parameters \nmodel = model.to(device)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-29T13:59:25.075990Z","iopub.execute_input":"2024-12-29T13:59:25.076284Z","iopub.status.idle":"2024-12-29T13:59:32.615179Z","shell.execute_reply.started":"2024-12-29T13:59:25.076261Z","shell.execute_reply":"2024-12-29T13:59:32.614223Z"}},"outputs":[{"name":"stdout","text":"Collecting efficientnet-pytorch==0.7.1\n  Downloading efficientnet_pytorch-0.7.1.tar.gz (21 kB)\n  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\nRequirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from efficientnet-pytorch==0.7.1) (2.4.1+cu121)\nRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->efficientnet-pytorch==0.7.1) (3.16.1)\nRequirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch->efficientnet-pytorch==0.7.1) (4.12.2)\nRequirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->efficientnet-pytorch==0.7.1) (1.13.3)\nRequirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->efficientnet-pytorch==0.7.1) (3.3)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->efficientnet-pytorch==0.7.1) (3.1.4)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->efficientnet-pytorch==0.7.1) (2024.6.1)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->efficientnet-pytorch==0.7.1) (2.1.5)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->efficientnet-pytorch==0.7.1) (1.3.0)\nBuilding wheels for collected packages: efficientnet-pytorch\n  Building wheel for efficientnet-pytorch (setup.py) ... \u001b[?25l\u001b[?25hdone\n  Created wheel for efficientnet-pytorch: filename=efficientnet_pytorch-0.7.1-py3-none-any.whl size=16425 sha256=ba6f62144b0a779a8f99dd53cba23564ae96fb7163424b26d97b2d7a34971e60\n  Stored in directory: /root/.cache/pip/wheels/03/3f/e9/911b1bc46869644912bda90a56bcf7b960f20b5187feea3baf\nSuccessfully built efficientnet-pytorch\nInstalling collected packages: efficientnet-pytorch\nSuccessfully installed efficientnet-pytorch-0.7.1\n","output_type":"stream"},{"name":"stderr","text":"Downloading: \"https://github.com/lukemelas/EfficientNet-PyTorch/releases/download/1.0/efficientnet-b0-355c32eb.pth\" to /root/.cache/torch/hub/checkpoints/efficientnet-b0-355c32eb.pth\n100%|██████████| 20.4M/20.4M [00:00<00:00, 101MB/s] \n","output_type":"stream"},{"name":"stdout","text":"Loaded pretrained weights for efficientnet-b0\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"# 9. 손실함수, 옵티마이저 정의 \nimport torch.nn as nn \ncriterion = nn.CrossEntropyLoss()\noptimizer = torch.optim.Adam(model.parameters(), lr=0.001)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-29T13:59:37.922428Z","iopub.execute_input":"2024-12-29T13:59:37.922911Z","iopub.status.idle":"2024-12-29T13:59:37.929769Z","shell.execute_reply.started":"2024-12-29T13:59:37.922866Z","shell.execute_reply":"2024-12-29T13:59:37.928787Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"# 10. 훈련, 검증, 최적 가중치 찾기를 위함 함수 개발 \n# 에폭 수만큼 훈련과 검증을 반복하면서 최적 모델의 가중치를 찾아서 마지막에 반환하는 구조다.\n# 데이터 로더를 이용하므로 훈련과 검증을 미니배치 단위로 수행한다.\n\nfrom sklearn.metrics import accuracy_score # 정확도 계산 함수\nfrom sklearn.metrics import recall_score   # 재현율 계산 함수\nfrom sklearn.metrics import f1_score       # F1 점수 계산 함수\nfrom tqdm.notebook import tqdm             # 진행률 표시 막대\n\ndef train(model, loader_train, loader_valid, criterion, optimizer, \n          scheduler=None, epochs=10, save_file='model_state_dict.pth'):\n    \n    valid_loss_min = np.inf # 최소 손실값 초기화 (검증 데이터용) \n\n    # 총 에폭만큼 반복\n    for epoch in range(epochs):\n        print(f'에폭 [{epoch+1}/{epochs}] \\n-----------------------------')\n        \n        # == [ 훈련 ] ==============================================\n        model.train()        # 모델을 훈련 상태로 설정\n        epoch_train_loss = 0 # 에폭별 손실값 초기화 (훈련 데이터용)\n        # '반복 횟수'만큼 반복 \n        for images, labels in tqdm(loader_train):\n            # 이미지, 레이블(타깃값) 데이터 미니배치를 장비에 할당 \n            images = images.to(device)\n            labels = labels.to(device)\n            \n            # 옵티마이저 내 기울기 초기화\n            optimizer.zero_grad()\n            # 순전파 : 이미지 데이터를 신경망 모델의 입력값으로 사용해 출력값 계산\n            outputs = model(images)\n            # 손실 함수를 활용해 outputs와 labels의 손실값 계산\n            loss = criterion(outputs, labels)\n            # 현재 배치에서의 손실 추가 (훈련 데이터용)\n            epoch_train_loss += loss.item() \n            loss.backward()       # 역전파 수행\n            optimizer.step()      # 가중치 갱신\n            if scheduler != None: # 스케줄러 학습률 갱신 \n                scheduler.step() \n\n        # 훈련 데이터 손실값 출력\n        print(f'\\t훈련 데이터 손실값 : {epoch_train_loss/len(loader_train):.4f}')\n        \n        # == [ 검증 ] ==============================================\n        model.eval()         # 모델을 평가 상태로 설정 \n        epoch_valid_loss = 0 # 에폭별 손실값 초기화 (검증 데이터용)\n        preds_list = []      # 예측값 저장용 리스트 초기화\n        true_list = []       # 실젯값 저장용 리스트 초기화\n        \n        with torch.no_grad(): # 기울기 계산 비활성화\n            for images, labels in loader_valid:\n                images = images.to(device)\n                labels = labels.to(device)\n                \n                outputs = model(images)\n                loss = criterion(outputs, labels)\n                epoch_valid_loss += loss.item()\n                \n                # 예측값 및 실제값 \n                preds = torch.max(outputs.cpu(), dim=1)[1].numpy() \n                true = labels.cpu().numpy() \n    \n                preds_list.extend(preds)\n                true_list.extend(true)\n                \n        # 정확도, 재현율, F1 점수 계산\n        val_accuracy = accuracy_score(true_list, preds_list)\n        val_recall = recall_score(true_list, preds_list)\n        val_f1_score = f1_score(true_list, preds_list)\n\n        # 검증 데이터 손실값 및 정확도, 재현율, F1점수 출력\n        print(f'\\t검증 데이터 손실값 : {epoch_valid_loss/len(loader_valid):.4f}')\n        print(f'\\t정확도 : {val_accuracy:.4f} / 재현율 : {val_recall:.4f} / F1 점수 : {val_f1_score:.4f}')\n        # == [ 최적 모델 가중치 찾기 ] ==============================\n        # 현 에폭에서의 손실값이 최소 손실값 이하면 모델 가중치 저장 \n        if epoch_valid_loss <= valid_loss_min: \n            print(f'\\t### 검증 데이터 손실값 감소 ({valid_loss_min:.4f} --> {epoch_valid_loss:.4f}). 모델 저장')\n            # 모델 가중치를 파일로 저장 \n            torch.save(model.state_dict(), save_file) \n            valid_loss_min = epoch_valid_loss # 최소 손실값 갱신 \n    return torch.load(save_file) # 저장한 모델 가중치를 불러와 반환","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-29T13:59:41.489076Z","iopub.execute_input":"2024-12-29T13:59:41.489420Z","iopub.status.idle":"2024-12-29T13:59:42.099503Z","shell.execute_reply.started":"2024-12-29T13:59:41.489391Z","shell.execute_reply":"2024-12-29T13:59:42.098589Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"# 11.train 함수로 훈련&검증 실행\nmodel_state_dict = train(model=model, loader_train=loader_train, loader_valid=loader_valid, criterion=criterion, optimizer=optimizer)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-29T14:00:04.922886Z","iopub.execute_input":"2024-12-29T14:00:04.923495Z","iopub.status.idle":"2024-12-29T14:10:17.119874Z","shell.execute_reply.started":"2024-12-29T14:00:04.923458Z","shell.execute_reply":"2024-12-29T14:10:17.118683Z"}},"outputs":[{"name":"stdout","text":"에폭 [1/10] \n-----------------------------\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/652 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3d11c501268d407b9d5ed752bddd5bd3"}},"metadata":{}},{"name":"stdout","text":"\t훈련 데이터 손실값 : 0.2076\n\t검증 데이터 손실값 : 0.4426\n\t정확도 : 0.8814 / 재현율 : 0.9897 / F1 점수 : 0.9125\n\t### 검증 데이터 손실값 감소 (inf --> 34.5198). 모델 저장\n에폭 [2/10] \n-----------------------------\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/652 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3c6a8c106de448379e11af0c93aeeaf7"}},"metadata":{}},{"name":"stdout","text":"\t훈련 데이터 손실값 : 0.1220\n\t검증 데이터 손실값 : 0.4628\n\t정확도 : 0.8301 / 재현율 : 0.9872 / F1 점수 : 0.8790\n에폭 [3/10] \n-----------------------------\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/652 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ca978a5a8a404795ab2badb5e443c1bf"}},"metadata":{}},{"name":"stdout","text":"\t훈련 데이터 손실값 : 0.1168\n\t검증 데이터 손실값 : 0.4504\n\t정확도 : 0.8846 / 재현율 : 0.9872 / F1 점수 : 0.9145\n에폭 [4/10] \n-----------------------------\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/652 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"248ba0c7bda6411f87a3054318497cbb"}},"metadata":{}},{"name":"stdout","text":"\t훈련 데이터 손실값 : 0.0960\n\t검증 데이터 손실값 : 0.3951\n\t정확도 : 0.8814 / 재현율 : 0.9821 / F1 점수 : 0.9119\n\t### 검증 데이터 손실값 감소 (34.5198 --> 30.8211). 모델 저장\n에폭 [5/10] \n-----------------------------\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/652 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c0f9dcc557aa4e6bb6cc54cea6c7092a"}},"metadata":{}},{"name":"stdout","text":"\t훈련 데이터 손실값 : 0.0936\n\t검증 데이터 손실값 : 0.6817\n\t정확도 : 0.8397 / 재현율 : 0.9974 / F1 점수 : 0.8861\n에폭 [6/10] \n-----------------------------\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/652 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fe1eed1ad4984be994d0a0f9e8688495"}},"metadata":{}},{"name":"stdout","text":"\t훈련 데이터 손실값 : 0.0755\n\t검증 데이터 손실값 : 0.3918\n\t정확도 : 0.8878 / 재현율 : 0.9667 / F1 점수 : 0.9150\n\t### 검증 데이터 손실값 감소 (30.8211 --> 30.5635). 모델 저장\n에폭 [7/10] \n-----------------------------\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/652 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"075b3fb92f1c4c80872a6571d5d09a25"}},"metadata":{}},{"name":"stdout","text":"\t훈련 데이터 손실값 : 0.0743\n\t검증 데이터 손실값 : 0.4793\n\t정확도 : 0.8622 / 재현율 : 0.9923 / F1 점수 : 0.9000\n에폭 [8/10] \n-----------------------------\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/652 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"70646a08275f4737b2bf066cf90f431e"}},"metadata":{}},{"name":"stdout","text":"\t훈련 데이터 손실값 : 0.0732\n\t검증 데이터 손실값 : 0.7541\n\t정확도 : 0.8221 / 재현율 : 0.9974 / F1 점수 : 0.8751\n에폭 [9/10] \n-----------------------------\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/652 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3850a21bccc94508816ca43c8b657a49"}},"metadata":{}},{"name":"stdout","text":"\t훈련 데이터 손실값 : 0.0698\n\t검증 데이터 손실값 : 0.6472\n\t정확도 : 0.8317 / 재현율 : 0.9974 / F1 점수 : 0.8811\n에폭 [10/10] \n-----------------------------\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/652 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2756a1484e9c4e7e98dbccae3de02dc8"}},"metadata":{}},{"name":"stdout","text":"\t훈련 데이터 손실값 : 0.0691\n\t검증 데이터 손실값 : 0.3909\n\t정확도 : 0.8926 / 재현율 : 0.9821 / F1 점수 : 0.9196\n\t### 검증 데이터 손실값 감소 (30.5635 --> 30.4871). 모델 저장\n","output_type":"stream"},{"name":"stderr","text":"<ipython-input-10-38d6a0076ed2>:81: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  return torch.load(save_file) # 저장한 모델 가중치를 불러와 반환\n","output_type":"stream"}],"execution_count":11},{"cell_type":"code","source":"# 12.최적 가중치로 모델 업데이트 \nmodel.load_state_dict(model_state_dict)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-29T14:10:17.121417Z","iopub.execute_input":"2024-12-29T14:10:17.121711Z","iopub.status.idle":"2024-12-29T14:10:17.140192Z","shell.execute_reply.started":"2024-12-29T14:10:17.121683Z","shell.execute_reply":"2024-12-29T14:10:17.139485Z"}},"outputs":[{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"<All keys matched successfully>"},"metadata":{}}],"execution_count":12},{"cell_type":"code","source":"# 13. 테스트 데이터로 예측실행 \n# 테스트 데이터와 로더를 정의하고, 테스트용 함수 개발 \ndataset_test = ImageFolder(root=test_path, transform=transform_test)\nloader_test = DataLoader(dataset=dataset_test, batch_size=batch_size, shuffle=False, worker_init_fn=seed_worker, generator=g, num_workers=2)\n\ndef predict(model, loader_test, return_true=False): \n    model.eval() \n    preds_list=[]\n    true_list=[]\n\n    with torch.no_grad(): \n        for images, labels in loader_test: \n            images=images.to(device)\n            labels=labels.to(device)\n            outputs = model(images)\n\n            preds = torch.max(outputs.cpu(), dim=1)[1].numpy()\n            preds_list.extend(preds)\n\n            true = labels.cpu().numpy()\n            true_list.extend(true)\n\n    if return_true: \n        return true_list, preds_list\n    else: \n        return preds_list","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-29T14:10:17.141512Z","iopub.execute_input":"2024-12-29T14:10:17.141775Z","iopub.status.idle":"2024-12-29T14:10:17.154181Z","shell.execute_reply.started":"2024-12-29T14:10:17.141754Z","shell.execute_reply":"2024-12-29T14:10:17.153340Z"}},"outputs":[],"execution_count":13},{"cell_type":"code","source":"# 14.predict 함수로 예측 실행 \ntrue_list, preds_list = predict(model=model, loader_test=loader_test, return_true=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-29T14:10:17.155219Z","iopub.execute_input":"2024-12-29T14:10:17.155486Z","iopub.status.idle":"2024-12-29T14:10:22.856606Z","shell.execute_reply.started":"2024-12-29T14:10:17.155465Z","shell.execute_reply":"2024-12-29T14:10:22.855382Z"}},"outputs":[],"execution_count":14},{"cell_type":"code","source":"# 15.평가지표 출력 \nprint('정확도 = ', accuracy_score(true_list, preds_list))\nprint('재현율 = ', recall_score(true_list, preds_list))\nprint('F1_socre = ', f1_score(true_list, preds_list))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-29T14:15:01.762408Z","iopub.execute_input":"2024-12-29T14:15:01.762831Z","iopub.status.idle":"2024-12-29T14:15:01.775286Z","shell.execute_reply.started":"2024-12-29T14:15:01.762797Z","shell.execute_reply":"2024-12-29T14:15:01.774383Z"}},"outputs":[{"name":"stdout","text":"정확도 =  0.8926282051282052\n재현율 =  0.982051282051282\nF1_socre =  0.9195678271308524\n","output_type":"stream"}],"execution_count":16},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}