## 1장. 생물의 눈과 기계의 눈 
- LeNet-5 : 얀 르쿤과 요슈아 벤지오에 의해 개발(1998). 거의 최초의 상용 딥러닝 애플리케이션. 미국 우정청의 ZIP코드 자동인식에 사용됨   
- 머신러닝은 feature enginnering의 비중이 크다. 반면 딥러닝은 feature engineering을 거의/전혀 사용하지 않는 대신 모델의 설계&튜닝에 집중한다.   
- AlexNet : 제프리 힌튼 팀에서 개발(2012). ILSVRC에서 압도적 성능을 보이며 딥러닝을 주류로 올려놓음   

## 2장. 사람의 언어와 기계의 언어   
- 딥러닝의 자연어 처리 : 단어 자체는 실제 의미가 없다, 언어의 문맥 안에서 사용될 때 그 의미를 알수 있다.   
- 자연어의 컴퓨터 처리를 위한 인코딩 (1) One-Hot encoding: 전통적인 머신러닝 기법에서 사용. 0과 1의 희소행렬로 단어의 위치정보를 기록    
- 자연어의 컴퓨터 처리를 위한 인코딩 (2) word vector : 다차원 공간 안의 의미있는 특정위치에 단어를 할당.   
  >  벡터공간의 한 단어에서 다른 단어로 의미 벡터를 따라 이동가능하므로, 단어 벡터 산술연산이 가능함 

| One-Hot | Vector |  
|---|---|  
|미묘한 점 없음 | 뉘앙스 많음 |  
|수동분류 | 자동분류 |  
|새로운 단어 x | 새로운 단어 O | 
|주관적 | 자연어 데이터에 의존 |  
|단어 유사도 x | 단어 유사도 = 벡터 공간상의 인접함 | 
|| 


- 머신러닝은 오디오 소리를 특정 음소로 인코딩하는 반면, 딥러닝은 자동으로 특성을 학습하여 음소를 예측함  

## 3장. 기계의 예술
- GAN : 적대적 신경망 모델, 굿펠로우에 의해 2014년 발표. 생성자와 판별자의 경쟁이 핵심 
- cf. Style transfer : https://junyanz.github.io/CycleGAN/ 
- cf. Sketch to Photo : https://mitmedialab.github.io/GAN-play/  

## 4장. 게임하는 기계 
- LSTM: NLP(자연어처리)의 많은 딥러닝 구조에서 사용되는 은닉층, 순환 신경망의 한종류로 시계열/재고현황/교통량/날씨등 순서대로 나열된 데이터에 적용된다. 
- 비지도 학습: 데이터 안애 내재된 감춰진 구조를 찾는 모델을 만드는 것이 목적. x는 있지만 예측할 출력 y가 없다. NLP에서 단어 벡터공간을 만드는 것도 비지도학습의 예이다. 
- 강화학습: 
  1. 어떤 환경 안에서 연속적인 행동을 받는 에이전트를 만드는 것으로 정의됨   
  2. 지도, 비지도 학습은 모델은 데이터에 영향을 미치지 않고 단순히 데이터를 사용할 뿐인데 반해,   
  3. 강화학습은 에이전트가 선택한 행동이 환경에서 에이전트로 제공하는 정보에 영향을 미침   
  

- 심층 강화학습 = 딥러닝 + 강화학습  

- Alphago vs. Alphago Zero 
  - 알파고는 초기 바둑선수의 기보를 지도학습 방법으로 훈련한 후, 강화학습으로 자기자신과 게임하며 훈련했음   
  - 반면 알파고 제로는 완전히 처음부터 바둑을 배우는 일반 지능에 더 가까운 신경망임 (도메인지식x, 사람의 개입x --> 순수하게 시행착오를 통해서만 학습. 3일동안 자신과 500만 게임 플레이) 

| 구분 | 내용 |   
|---|---|  
| 약 인공지능 | 특정작업에 전문화된 기계의 능력 | 
| 일반 인공지능(AGI) | 다수의 작업을 잘 수행할 수 있는 하나의 알고리즘 | 
| 초 인공지능(ASI) | 인간의 지적능력을 뛰어넘는 알고리즘 |   
|