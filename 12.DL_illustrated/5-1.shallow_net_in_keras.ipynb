{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "879b02f9",
   "metadata": {},
   "source": [
    "### 5-1. 케라스로 얕은 신경망 만들기 \n",
    "- MNIST 손글씨 분류 \n",
    "- 입력층(28x28=784) -> 은닉층(64개 뉴런, sigmoid) -> 출력층(10개 뉴런, softmax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c98901c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "os.environ['TF_METAL_LOGGING'] = '0'\n",
    "\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "    except RuntimeError as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5a69b871",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version: 2.16.1\n",
      "GPU Available: [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "\n",
    "print(\"TensorFlow version:\", tf.__version__)\n",
    "print(\"GPU Available:\", tf.config.list_physical_devices('GPU'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2be895a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mnist dataset loading \n",
    "(X_train, y_train), (X_valid, y_valid) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8e1d6d05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28) (60000,) (10000, 28, 28) (10000,)\n",
      "3\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 200x200 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 데이터 확인 \n",
    "print(X_train.shape, y_train.shape, X_valid.shape, y_valid.shape)\n",
    "\n",
    "temp_num = 500\n",
    "\n",
    "plt.figure(figsize=(2,2))\n",
    "plt.imshow(X_train[temp_num], cmap='grey')\n",
    "print(y_train[temp_num])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "089b8d5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x500 with 12 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(5, 5))\n",
    "for k in range(12): \n",
    "    plt.subplot(3, 4, k+1)\n",
    "    plt.imshow(X_train[k], cmap='Greys')\n",
    "    plt.axis('off')\n",
    "    plt.title(str(y_train[k]), fontsize=10)  # ← 여기에 라벨 표시\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bfda7d6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.01176471, 0.07058824, 0.07058824,\n",
       "       0.07058824, 0.49411765, 0.53333336, 0.6862745 , 0.10196079,\n",
       "       0.6509804 , 1.        , 0.96862745, 0.49803922, 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.11764706, 0.14117648, 0.36862746, 0.6039216 ,\n",
       "       0.6666667 , 0.99215686, 0.99215686, 0.99215686, 0.99215686,\n",
       "       0.99215686, 0.88235295, 0.6745098 , 0.99215686, 0.9490196 ,\n",
       "       0.7647059 , 0.2509804 , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.19215687, 0.93333334,\n",
       "       0.99215686, 0.99215686, 0.99215686, 0.99215686, 0.99215686,\n",
       "       0.99215686, 0.99215686, 0.99215686, 0.9843137 , 0.3647059 ,\n",
       "       0.32156864, 0.32156864, 0.21960784, 0.15294118, 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.07058824, 0.85882354, 0.99215686, 0.99215686,\n",
       "       0.99215686, 0.99215686, 0.99215686, 0.7764706 , 0.7137255 ,\n",
       "       0.96862745, 0.94509804, 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.3137255 , 0.6117647 , 0.41960785, 0.99215686, 0.99215686,\n",
       "       0.8039216 , 0.04313726, 0.        , 0.16862746, 0.6039216 ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.05490196,\n",
       "       0.00392157, 0.6039216 , 0.99215686, 0.3529412 , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.54509807,\n",
       "       0.99215686, 0.74509805, 0.00784314, 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.04313726, 0.74509805, 0.99215686,\n",
       "       0.27450982, 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.13725491, 0.94509804, 0.88235295, 0.627451  ,\n",
       "       0.42352942, 0.00392157, 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.31764707, 0.9411765 , 0.99215686, 0.99215686, 0.46666667,\n",
       "       0.09803922, 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.1764706 ,\n",
       "       0.7294118 , 0.99215686, 0.99215686, 0.5882353 , 0.10588235,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.0627451 , 0.3647059 ,\n",
       "       0.9882353 , 0.99215686, 0.73333335, 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.9764706 , 0.99215686,\n",
       "       0.9764706 , 0.2509804 , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.18039216, 0.50980395,\n",
       "       0.7176471 , 0.99215686, 0.99215686, 0.8117647 , 0.00784314,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.15294118,\n",
       "       0.5803922 , 0.8980392 , 0.99215686, 0.99215686, 0.99215686,\n",
       "       0.98039216, 0.7137255 , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.09411765, 0.44705883, 0.8666667 , 0.99215686, 0.99215686,\n",
       "       0.99215686, 0.99215686, 0.7882353 , 0.30588236, 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.09019608, 0.25882354, 0.8352941 , 0.99215686,\n",
       "       0.99215686, 0.99215686, 0.99215686, 0.7764706 , 0.31764707,\n",
       "       0.00784314, 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.07058824, 0.67058825, 0.85882354,\n",
       "       0.99215686, 0.99215686, 0.99215686, 0.99215686, 0.7647059 ,\n",
       "       0.3137255 , 0.03529412, 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.21568628, 0.6745098 ,\n",
       "       0.8862745 , 0.99215686, 0.99215686, 0.99215686, 0.99215686,\n",
       "       0.95686275, 0.52156866, 0.04313726, 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.53333336, 0.99215686, 0.99215686, 0.99215686,\n",
       "       0.83137256, 0.5294118 , 0.5176471 , 0.0627451 , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        ], dtype=float32)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# X값 변환 \n",
    "# 2차원(28x28) -> 1차원(784) 펼치기 \n",
    "X_train = X_train.reshape(60000, 784).astype('float32')\n",
    "X_valid = X_valid.reshape(10000, 784).astype('float32')\n",
    "\n",
    "# 모든 값을  0~1 사이의 실수로 변환 \n",
    "X_train /= 255\n",
    "X_valid /= 255 \n",
    "\n",
    "X_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d370b37c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 1., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# y값 변환 : One-Hot encoding \n",
    "n_classes = 10 \n",
    "y_train = keras.utils.to_categorical(y_train, n_classes)\n",
    "y_valid = keras.utils.to_categorical(y_valid, n_classes)\n",
    "\n",
    "y_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d28d9e00",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yb_choi/Downloads/yes/envs/tf_metal/lib/python3.10/site-packages/keras/src/layers/core/dense.py:93: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "2025-06-08 23:18:35.562245: I metal_plugin/src/device/metal_device.cc:1154] Metal device set to: Apple M4\n",
      "2025-06-08 23:18:35.562261: I metal_plugin/src/device/metal_device.cc:296] systemMemory: 16.00 GB\n",
      "2025-06-08 23:18:35.562266: I metal_plugin/src/device/metal_device.cc:313] maxCacheSize: 5.33 GB\n",
      "2025-06-08 23:18:35.562296: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2025-06-08 23:18:35.562306: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    }
   ],
   "source": [
    "# 신경망 생성 \n",
    "model = Sequential()\n",
    "model.add(Dense(64, activation='sigmoid', input_shape=(784,)))\n",
    "model.add(Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f5db8d2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │        <span style=\"color: #00af00; text-decoration-color: #00af00\">50,240</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">650</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │        \u001b[38;5;34m50,240\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             │           \u001b[38;5;34m650\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">50,890</span> (198.79 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m50,890\u001b[0m (198.79 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">50,890</span> (198.79 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m50,890\u001b[0m (198.79 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "335962ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile\n",
    "model.compile(loss='categorical_crossentropy', optimizer=SGD(learning_rate=0.01), metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5c2c08bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "\u001b[1m  1/469\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:51\u001b[0m 239ms/step - accuracy: 0.0703 - loss: 2.5178"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-08 23:18:35.819603: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:117] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.3098 - loss: 2.1911 - val_accuracy: 0.6631 - val_loss: 1.8024\n",
      "Epoch 2/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.6773 - loss: 1.7083 - val_accuracy: 0.7609 - val_loss: 1.4165\n",
      "Epoch 3/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.7593 - loss: 1.3513 - val_accuracy: 0.8034 - val_loss: 1.1353\n",
      "Epoch 4/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.8027 - loss: 1.0952 - val_accuracy: 0.8282 - val_loss: 0.9453\n",
      "Epoch 5/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.8266 - loss: 0.9253 - val_accuracy: 0.8440 - val_loss: 0.8161\n",
      "Epoch 6/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.8417 - loss: 0.8082 - val_accuracy: 0.8544 - val_loss: 0.7253\n",
      "Epoch 7/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.8489 - loss: 0.7263 - val_accuracy: 0.8625 - val_loss: 0.6586\n",
      "Epoch 8/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.8606 - loss: 0.6578 - val_accuracy: 0.8698 - val_loss: 0.6078\n",
      "Epoch 9/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.8625 - loss: 0.6150 - val_accuracy: 0.8752 - val_loss: 0.5680\n",
      "Epoch 10/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.8680 - loss: 0.5761 - val_accuracy: 0.8771 - val_loss: 0.5360\n",
      "Epoch 11/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.8710 - loss: 0.5464 - val_accuracy: 0.8820 - val_loss: 0.5098\n",
      "Epoch 12/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.8756 - loss: 0.5232 - val_accuracy: 0.8842 - val_loss: 0.4879\n",
      "Epoch 13/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.8796 - loss: 0.4964 - val_accuracy: 0.8875 - val_loss: 0.4691\n",
      "Epoch 14/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.8824 - loss: 0.4806 - val_accuracy: 0.8901 - val_loss: 0.4532\n",
      "Epoch 15/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.8841 - loss: 0.4612 - val_accuracy: 0.8906 - val_loss: 0.4391\n",
      "Epoch 16/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.8842 - loss: 0.4559 - val_accuracy: 0.8926 - val_loss: 0.4269\n",
      "Epoch 17/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.8885 - loss: 0.4425 - val_accuracy: 0.8942 - val_loss: 0.4162\n",
      "Epoch 18/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.8882 - loss: 0.4309 - val_accuracy: 0.8966 - val_loss: 0.4064\n",
      "Epoch 19/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.8910 - loss: 0.4196 - val_accuracy: 0.8984 - val_loss: 0.3977\n",
      "Epoch 20/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.8918 - loss: 0.4116 - val_accuracy: 0.8991 - val_loss: 0.3898\n",
      "Epoch 21/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.8951 - loss: 0.4000 - val_accuracy: 0.9005 - val_loss: 0.3826\n",
      "Epoch 22/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.8948 - loss: 0.3972 - val_accuracy: 0.9013 - val_loss: 0.3763\n",
      "Epoch 23/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.8959 - loss: 0.3873 - val_accuracy: 0.9025 - val_loss: 0.3701\n",
      "Epoch 24/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.8979 - loss: 0.3803 - val_accuracy: 0.9033 - val_loss: 0.3646\n",
      "Epoch 25/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.8973 - loss: 0.3757 - val_accuracy: 0.9035 - val_loss: 0.3596\n",
      "Epoch 26/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.8990 - loss: 0.3695 - val_accuracy: 0.9049 - val_loss: 0.3548\n",
      "Epoch 27/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.8985 - loss: 0.3703 - val_accuracy: 0.9049 - val_loss: 0.3502\n",
      "Epoch 28/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.8996 - loss: 0.3658 - val_accuracy: 0.9057 - val_loss: 0.3464\n",
      "Epoch 29/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.9000 - loss: 0.3622 - val_accuracy: 0.9064 - val_loss: 0.3421\n",
      "Epoch 30/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.9017 - loss: 0.3559 - val_accuracy: 0.9076 - val_loss: 0.3384\n",
      "Epoch 31/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.9018 - loss: 0.3512 - val_accuracy: 0.9080 - val_loss: 0.3352\n",
      "Epoch 32/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.9035 - loss: 0.3461 - val_accuracy: 0.9086 - val_loss: 0.3318\n",
      "Epoch 33/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.9030 - loss: 0.3419 - val_accuracy: 0.9100 - val_loss: 0.3289\n",
      "Epoch 34/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.9033 - loss: 0.3425 - val_accuracy: 0.9104 - val_loss: 0.3257\n",
      "Epoch 35/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.9054 - loss: 0.3408 - val_accuracy: 0.9109 - val_loss: 0.3231\n",
      "Epoch 36/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.9049 - loss: 0.3358 - val_accuracy: 0.9117 - val_loss: 0.3202\n",
      "Epoch 37/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.9081 - loss: 0.3309 - val_accuracy: 0.9126 - val_loss: 0.3177\n",
      "Epoch 38/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.9079 - loss: 0.3301 - val_accuracy: 0.9132 - val_loss: 0.3152\n",
      "Epoch 39/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.9089 - loss: 0.3242 - val_accuracy: 0.9137 - val_loss: 0.3129\n",
      "Epoch 40/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.9088 - loss: 0.3246 - val_accuracy: 0.9137 - val_loss: 0.3107\n",
      "Epoch 41/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.9104 - loss: 0.3184 - val_accuracy: 0.9139 - val_loss: 0.3086\n",
      "Epoch 42/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.9103 - loss: 0.3179 - val_accuracy: 0.9156 - val_loss: 0.3065\n",
      "Epoch 43/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.9113 - loss: 0.3141 - val_accuracy: 0.9158 - val_loss: 0.3045\n",
      "Epoch 44/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.9125 - loss: 0.3098 - val_accuracy: 0.9161 - val_loss: 0.3024\n",
      "Epoch 45/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.9137 - loss: 0.3072 - val_accuracy: 0.9168 - val_loss: 0.3005\n",
      "Epoch 46/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.9139 - loss: 0.3090 - val_accuracy: 0.9170 - val_loss: 0.2988\n",
      "Epoch 47/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.9152 - loss: 0.3032 - val_accuracy: 0.9179 - val_loss: 0.2970\n",
      "Epoch 48/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.9146 - loss: 0.3037 - val_accuracy: 0.9173 - val_loss: 0.2954\n",
      "Epoch 49/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.9153 - loss: 0.3011 - val_accuracy: 0.9177 - val_loss: 0.2935\n",
      "Epoch 50/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.9149 - loss: 0.3074 - val_accuracy: 0.9196 - val_loss: 0.2919\n",
      "Epoch 51/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.9153 - loss: 0.3011 - val_accuracy: 0.9198 - val_loss: 0.2903\n",
      "Epoch 52/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.9149 - loss: 0.3008 - val_accuracy: 0.9208 - val_loss: 0.2888\n",
      "Epoch 53/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.9152 - loss: 0.2994 - val_accuracy: 0.9208 - val_loss: 0.2873\n",
      "Epoch 54/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.9169 - loss: 0.2933 - val_accuracy: 0.9210 - val_loss: 0.2860\n",
      "Epoch 55/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.9157 - loss: 0.2973 - val_accuracy: 0.9211 - val_loss: 0.2847\n",
      "Epoch 56/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.9177 - loss: 0.2949 - val_accuracy: 0.9214 - val_loss: 0.2830\n",
      "Epoch 57/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.9177 - loss: 0.2904 - val_accuracy: 0.9217 - val_loss: 0.2818\n",
      "Epoch 58/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.9203 - loss: 0.2860 - val_accuracy: 0.9217 - val_loss: 0.2802\n",
      "Epoch 59/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.9180 - loss: 0.2861 - val_accuracy: 0.9224 - val_loss: 0.2790\n",
      "Epoch 60/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.9196 - loss: 0.2832 - val_accuracy: 0.9229 - val_loss: 0.2776\n",
      "Epoch 61/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.9218 - loss: 0.2808 - val_accuracy: 0.9230 - val_loss: 0.2762\n",
      "Epoch 62/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.9189 - loss: 0.2862 - val_accuracy: 0.9242 - val_loss: 0.2750\n",
      "Epoch 63/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.9199 - loss: 0.2838 - val_accuracy: 0.9243 - val_loss: 0.2738\n",
      "Epoch 64/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.9211 - loss: 0.2787 - val_accuracy: 0.9248 - val_loss: 0.2727\n",
      "Epoch 65/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.9224 - loss: 0.2728 - val_accuracy: 0.9245 - val_loss: 0.2714\n",
      "Epoch 66/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.9212 - loss: 0.2745 - val_accuracy: 0.9245 - val_loss: 0.2702\n",
      "Epoch 67/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.9219 - loss: 0.2748 - val_accuracy: 0.9253 - val_loss: 0.2692\n",
      "Epoch 68/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.9215 - loss: 0.2767 - val_accuracy: 0.9257 - val_loss: 0.2680\n",
      "Epoch 69/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.9226 - loss: 0.2752 - val_accuracy: 0.9262 - val_loss: 0.2669\n",
      "Epoch 70/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.9231 - loss: 0.2718 - val_accuracy: 0.9267 - val_loss: 0.2660\n",
      "Epoch 71/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.9244 - loss: 0.2703 - val_accuracy: 0.9265 - val_loss: 0.2646\n",
      "Epoch 72/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.9242 - loss: 0.2705 - val_accuracy: 0.9270 - val_loss: 0.2635\n",
      "Epoch 73/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.9234 - loss: 0.2670 - val_accuracy: 0.9273 - val_loss: 0.2625\n",
      "Epoch 74/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.9252 - loss: 0.2639 - val_accuracy: 0.9278 - val_loss: 0.2614\n",
      "Epoch 75/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.9257 - loss: 0.2662 - val_accuracy: 0.9277 - val_loss: 0.2605\n",
      "Epoch 76/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.9247 - loss: 0.2627 - val_accuracy: 0.9280 - val_loss: 0.2595\n",
      "Epoch 77/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.9258 - loss: 0.2649 - val_accuracy: 0.9281 - val_loss: 0.2584\n",
      "Epoch 78/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.9257 - loss: 0.2640 - val_accuracy: 0.9285 - val_loss: 0.2575\n",
      "Epoch 79/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.9267 - loss: 0.2612 - val_accuracy: 0.9288 - val_loss: 0.2564\n",
      "Epoch 80/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.9270 - loss: 0.2572 - val_accuracy: 0.9291 - val_loss: 0.2555\n",
      "Epoch 81/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.9280 - loss: 0.2559 - val_accuracy: 0.9295 - val_loss: 0.2545\n",
      "Epoch 82/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.9276 - loss: 0.2582 - val_accuracy: 0.9292 - val_loss: 0.2535\n",
      "Epoch 83/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.9257 - loss: 0.2614 - val_accuracy: 0.9296 - val_loss: 0.2527\n",
      "Epoch 84/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.9267 - loss: 0.2560 - val_accuracy: 0.9302 - val_loss: 0.2518\n",
      "Epoch 85/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - accuracy: 0.9279 - loss: 0.2573 - val_accuracy: 0.9302 - val_loss: 0.2507\n",
      "Epoch 86/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.9277 - loss: 0.2518 - val_accuracy: 0.9312 - val_loss: 0.2499\n",
      "Epoch 87/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.9278 - loss: 0.2555 - val_accuracy: 0.9312 - val_loss: 0.2490\n",
      "Epoch 88/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.9288 - loss: 0.2519 - val_accuracy: 0.9308 - val_loss: 0.2480\n",
      "Epoch 89/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.9293 - loss: 0.2504 - val_accuracy: 0.9320 - val_loss: 0.2471\n",
      "Epoch 90/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.9297 - loss: 0.2489 - val_accuracy: 0.9323 - val_loss: 0.2464\n",
      "Epoch 91/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.9304 - loss: 0.2462 - val_accuracy: 0.9323 - val_loss: 0.2454\n",
      "Epoch 92/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.9287 - loss: 0.2507 - val_accuracy: 0.9324 - val_loss: 0.2446\n",
      "Epoch 93/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.9303 - loss: 0.2472 - val_accuracy: 0.9327 - val_loss: 0.2436\n",
      "Epoch 94/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.9293 - loss: 0.2473 - val_accuracy: 0.9330 - val_loss: 0.2428\n",
      "Epoch 95/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.9310 - loss: 0.2460 - val_accuracy: 0.9330 - val_loss: 0.2420\n",
      "Epoch 96/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.9309 - loss: 0.2445 - val_accuracy: 0.9328 - val_loss: 0.2412\n",
      "Epoch 97/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.9303 - loss: 0.2448 - val_accuracy: 0.9337 - val_loss: 0.2402\n",
      "Epoch 98/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.9313 - loss: 0.2422 - val_accuracy: 0.9336 - val_loss: 0.2396\n",
      "Epoch 99/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.9305 - loss: 0.2445 - val_accuracy: 0.9340 - val_loss: 0.2388\n",
      "Epoch 100/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.9310 - loss: 0.2456 - val_accuracy: 0.9336 - val_loss: 0.2380\n",
      "Epoch 101/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.9321 - loss: 0.2403 - val_accuracy: 0.9346 - val_loss: 0.2371\n",
      "Epoch 102/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.9332 - loss: 0.2397 - val_accuracy: 0.9343 - val_loss: 0.2364\n",
      "Epoch 103/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.9313 - loss: 0.2423 - val_accuracy: 0.9351 - val_loss: 0.2355\n",
      "Epoch 104/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.9315 - loss: 0.2425 - val_accuracy: 0.9347 - val_loss: 0.2348\n",
      "Epoch 105/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.9344 - loss: 0.2345 - val_accuracy: 0.9348 - val_loss: 0.2340\n",
      "Epoch 106/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.9333 - loss: 0.2367 - val_accuracy: 0.9347 - val_loss: 0.2333\n",
      "Epoch 107/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.9347 - loss: 0.2324 - val_accuracy: 0.9351 - val_loss: 0.2326\n",
      "Epoch 108/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.9354 - loss: 0.2302 - val_accuracy: 0.9354 - val_loss: 0.2317\n",
      "Epoch 109/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.9338 - loss: 0.2337 - val_accuracy: 0.9355 - val_loss: 0.2310\n",
      "Epoch 110/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.9331 - loss: 0.2375 - val_accuracy: 0.9357 - val_loss: 0.2302\n",
      "Epoch 111/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.9344 - loss: 0.2294 - val_accuracy: 0.9355 - val_loss: 0.2295\n",
      "Epoch 112/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.9322 - loss: 0.2377 - val_accuracy: 0.9359 - val_loss: 0.2288\n",
      "Epoch 113/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.9349 - loss: 0.2311 - val_accuracy: 0.9364 - val_loss: 0.2281\n",
      "Epoch 114/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.9345 - loss: 0.2297 - val_accuracy: 0.9361 - val_loss: 0.2274\n",
      "Epoch 115/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.9359 - loss: 0.2282 - val_accuracy: 0.9364 - val_loss: 0.2267\n",
      "Epoch 116/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.9350 - loss: 0.2274 - val_accuracy: 0.9369 - val_loss: 0.2260\n",
      "Epoch 117/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.9346 - loss: 0.2258 - val_accuracy: 0.9366 - val_loss: 0.2252\n",
      "Epoch 118/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.9371 - loss: 0.2246 - val_accuracy: 0.9377 - val_loss: 0.2246\n",
      "Epoch 119/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.9359 - loss: 0.2229 - val_accuracy: 0.9376 - val_loss: 0.2239\n",
      "Epoch 120/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.9365 - loss: 0.2212 - val_accuracy: 0.9380 - val_loss: 0.2232\n",
      "Epoch 121/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.9384 - loss: 0.2195 - val_accuracy: 0.9377 - val_loss: 0.2226\n",
      "Epoch 122/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.9355 - loss: 0.2256 - val_accuracy: 0.9385 - val_loss: 0.2219\n",
      "Epoch 123/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.9354 - loss: 0.2246 - val_accuracy: 0.9383 - val_loss: 0.2212\n",
      "Epoch 124/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.9378 - loss: 0.2194 - val_accuracy: 0.9379 - val_loss: 0.2205\n",
      "Epoch 125/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.9377 - loss: 0.2198 - val_accuracy: 0.9383 - val_loss: 0.2199\n",
      "Epoch 126/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.9368 - loss: 0.2271 - val_accuracy: 0.9386 - val_loss: 0.2193\n",
      "Epoch 127/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.9382 - loss: 0.2201 - val_accuracy: 0.9388 - val_loss: 0.2185\n",
      "Epoch 128/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.9370 - loss: 0.2185 - val_accuracy: 0.9393 - val_loss: 0.2180\n",
      "Epoch 129/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.9392 - loss: 0.2144 - val_accuracy: 0.9395 - val_loss: 0.2174\n",
      "Epoch 130/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.9399 - loss: 0.2149 - val_accuracy: 0.9396 - val_loss: 0.2167\n",
      "Epoch 131/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.9384 - loss: 0.2170 - val_accuracy: 0.9394 - val_loss: 0.2161\n",
      "Epoch 132/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.9388 - loss: 0.2141 - val_accuracy: 0.9396 - val_loss: 0.2155\n",
      "Epoch 133/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.9403 - loss: 0.2106 - val_accuracy: 0.9395 - val_loss: 0.2148\n",
      "Epoch 134/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.9382 - loss: 0.2153 - val_accuracy: 0.9403 - val_loss: 0.2141\n",
      "Epoch 135/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.9409 - loss: 0.2067 - val_accuracy: 0.9394 - val_loss: 0.2136\n",
      "Epoch 136/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.9390 - loss: 0.2147 - val_accuracy: 0.9402 - val_loss: 0.2130\n",
      "Epoch 137/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.9417 - loss: 0.2080 - val_accuracy: 0.9402 - val_loss: 0.2123\n",
      "Epoch 138/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.9402 - loss: 0.2122 - val_accuracy: 0.9401 - val_loss: 0.2118\n",
      "Epoch 139/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.9393 - loss: 0.2125 - val_accuracy: 0.9405 - val_loss: 0.2111\n",
      "Epoch 140/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.9411 - loss: 0.2086 - val_accuracy: 0.9407 - val_loss: 0.2107\n",
      "Epoch 141/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.9425 - loss: 0.2043 - val_accuracy: 0.9411 - val_loss: 0.2099\n",
      "Epoch 142/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.9400 - loss: 0.2077 - val_accuracy: 0.9408 - val_loss: 0.2093\n",
      "Epoch 143/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.9397 - loss: 0.2091 - val_accuracy: 0.9410 - val_loss: 0.2089\n",
      "Epoch 144/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.9413 - loss: 0.2076 - val_accuracy: 0.9412 - val_loss: 0.2083\n",
      "Epoch 145/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.9409 - loss: 0.2079 - val_accuracy: 0.9410 - val_loss: 0.2078\n",
      "Epoch 146/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.9423 - loss: 0.2058 - val_accuracy: 0.9413 - val_loss: 0.2071\n",
      "Epoch 147/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.9422 - loss: 0.2052 - val_accuracy: 0.9415 - val_loss: 0.2066\n",
      "Epoch 148/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.9414 - loss: 0.2071 - val_accuracy: 0.9417 - val_loss: 0.2061\n",
      "Epoch 149/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.9439 - loss: 0.1993 - val_accuracy: 0.9415 - val_loss: 0.2056\n",
      "Epoch 150/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.9432 - loss: 0.2031 - val_accuracy: 0.9417 - val_loss: 0.2049\n",
      "Epoch 151/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.9428 - loss: 0.1990 - val_accuracy: 0.9419 - val_loss: 0.2046\n",
      "Epoch 152/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.9401 - loss: 0.2093 - val_accuracy: 0.9423 - val_loss: 0.2039\n",
      "Epoch 153/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.9409 - loss: 0.2050 - val_accuracy: 0.9422 - val_loss: 0.2034\n",
      "Epoch 154/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.9423 - loss: 0.2028 - val_accuracy: 0.9425 - val_loss: 0.2029\n",
      "Epoch 155/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.9432 - loss: 0.2006 - val_accuracy: 0.9424 - val_loss: 0.2025\n",
      "Epoch 156/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.9432 - loss: 0.2015 - val_accuracy: 0.9425 - val_loss: 0.2018\n",
      "Epoch 157/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.9423 - loss: 0.2011 - val_accuracy: 0.9429 - val_loss: 0.2014\n",
      "Epoch 158/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.9441 - loss: 0.1989 - val_accuracy: 0.9429 - val_loss: 0.2008\n",
      "Epoch 159/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.9448 - loss: 0.1964 - val_accuracy: 0.9431 - val_loss: 0.2002\n",
      "Epoch 160/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.9442 - loss: 0.1958 - val_accuracy: 0.9431 - val_loss: 0.1997\n",
      "Epoch 161/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.9441 - loss: 0.1998 - val_accuracy: 0.9434 - val_loss: 0.1992\n",
      "Epoch 162/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.9446 - loss: 0.1954 - val_accuracy: 0.9434 - val_loss: 0.1987\n",
      "Epoch 163/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.9437 - loss: 0.1995 - val_accuracy: 0.9436 - val_loss: 0.1982\n",
      "Epoch 164/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.9415 - loss: 0.2015 - val_accuracy: 0.9437 - val_loss: 0.1979\n",
      "Epoch 165/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.9451 - loss: 0.1921 - val_accuracy: 0.9443 - val_loss: 0.1972\n",
      "Epoch 166/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.9445 - loss: 0.1948 - val_accuracy: 0.9444 - val_loss: 0.1967\n",
      "Epoch 167/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.9443 - loss: 0.1958 - val_accuracy: 0.9439 - val_loss: 0.1963\n",
      "Epoch 168/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.9463 - loss: 0.1909 - val_accuracy: 0.9449 - val_loss: 0.1958\n",
      "Epoch 169/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.9428 - loss: 0.1996 - val_accuracy: 0.9447 - val_loss: 0.1952\n",
      "Epoch 170/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.9450 - loss: 0.1934 - val_accuracy: 0.9445 - val_loss: 0.1948\n",
      "Epoch 171/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.9453 - loss: 0.1935 - val_accuracy: 0.9450 - val_loss: 0.1943\n",
      "Epoch 172/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.9452 - loss: 0.1910 - val_accuracy: 0.9450 - val_loss: 0.1939\n",
      "Epoch 173/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.9451 - loss: 0.1912 - val_accuracy: 0.9450 - val_loss: 0.1933\n",
      "Epoch 174/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.9466 - loss: 0.1898 - val_accuracy: 0.9454 - val_loss: 0.1930\n",
      "Epoch 175/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.9462 - loss: 0.1873 - val_accuracy: 0.9452 - val_loss: 0.1925\n",
      "Epoch 176/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.9466 - loss: 0.1883 - val_accuracy: 0.9456 - val_loss: 0.1921\n",
      "Epoch 177/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.9469 - loss: 0.1867 - val_accuracy: 0.9455 - val_loss: 0.1916\n",
      "Epoch 178/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.9478 - loss: 0.1837 - val_accuracy: 0.9460 - val_loss: 0.1911\n",
      "Epoch 179/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.9471 - loss: 0.1860 - val_accuracy: 0.9460 - val_loss: 0.1907\n",
      "Epoch 180/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.9463 - loss: 0.1898 - val_accuracy: 0.9461 - val_loss: 0.1902\n",
      "Epoch 181/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.9449 - loss: 0.1916 - val_accuracy: 0.9460 - val_loss: 0.1897\n",
      "Epoch 182/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.9477 - loss: 0.1829 - val_accuracy: 0.9460 - val_loss: 0.1894\n",
      "Epoch 183/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.9470 - loss: 0.1886 - val_accuracy: 0.9462 - val_loss: 0.1890\n",
      "Epoch 184/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.9477 - loss: 0.1853 - val_accuracy: 0.9461 - val_loss: 0.1885\n",
      "Epoch 185/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.9483 - loss: 0.1855 - val_accuracy: 0.9469 - val_loss: 0.1880\n",
      "Epoch 186/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.9471 - loss: 0.1858 - val_accuracy: 0.9468 - val_loss: 0.1876\n",
      "Epoch 187/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.9490 - loss: 0.1853 - val_accuracy: 0.9467 - val_loss: 0.1872\n",
      "Epoch 188/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.9460 - loss: 0.1892 - val_accuracy: 0.9471 - val_loss: 0.1867\n",
      "Epoch 189/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.9478 - loss: 0.1843 - val_accuracy: 0.9470 - val_loss: 0.1863\n",
      "Epoch 190/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.9483 - loss: 0.1827 - val_accuracy: 0.9480 - val_loss: 0.1859\n",
      "Epoch 191/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.9498 - loss: 0.1783 - val_accuracy: 0.9472 - val_loss: 0.1855\n",
      "Epoch 192/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.9479 - loss: 0.1825 - val_accuracy: 0.9478 - val_loss: 0.1851\n",
      "Epoch 193/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.9489 - loss: 0.1810 - val_accuracy: 0.9476 - val_loss: 0.1847\n",
      "Epoch 194/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.9486 - loss: 0.1808 - val_accuracy: 0.9477 - val_loss: 0.1843\n",
      "Epoch 195/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.9480 - loss: 0.1815 - val_accuracy: 0.9479 - val_loss: 0.1838\n",
      "Epoch 196/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.9486 - loss: 0.1826 - val_accuracy: 0.9481 - val_loss: 0.1835\n",
      "Epoch 197/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.9489 - loss: 0.1786 - val_accuracy: 0.9481 - val_loss: 0.1830\n",
      "Epoch 198/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.9486 - loss: 0.1790 - val_accuracy: 0.9481 - val_loss: 0.1827\n",
      "Epoch 199/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.9483 - loss: 0.1813 - val_accuracy: 0.9482 - val_loss: 0.1823\n",
      "Epoch 200/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.9510 - loss: 0.1747 - val_accuracy: 0.9485 - val_loss: 0.1819\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x16b057310>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 신경망 훈련 \n",
    "model.fit(X_train, y_train, \n",
    "          batch_size=128, epochs=200, \n",
    "          verbose=1, \n",
    "          validation_data=(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4fff2991",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9395 - loss: 0.2081\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.1819320172071457, 0.9484999775886536]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 모델평가 \n",
    "model.evaluate(X_valid, y_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06e05d39",
   "metadata": {},
   "source": [
    "### 결론 요약:\n",
    "- 이 모델은 검증 데이터셋에서 약 94.85%의 정확도를 보이고 있음 \n",
    "- 손실 함수 값인 loss ≒ 0.18은 모델이 예측에서 얼마나 많이 틀렸는지를 정량적으로 보여주는 값 → 낮을수록 좋음\n",
    "- 즉, 단일 은닉층(sigmoid 64)만으로도 MNIST에서 꽤 양호한 결과를 내고 있다는 뜻입니다.\n",
    "- 향후 정확도를 더 높이려면 ReLU, Dropout, 더 깊은 네트워크, BatchNormalization, Adam 옵티마이저 등을 도입해볼 수 있습니다. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c789fa5",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_metal",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
